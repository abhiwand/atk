************************************
* Intel(R) Graph Builder 2.0-alpha *
************************************

Intel Graph Builder 2.0 is a library of user defined functions (UDF's) and
macros in Pig Latin to construct graphs in Hadoop(TM). The 2.0-alpha version
supports multi-relational graphs, or property graphs, in which both objects
and relationships may be labeled with multiple properties and property values.
Graphs can be constructed from structured, semi-structured,
or unstructured data. In case of structured data, columns of HBase tables or
fields in CSV/TSV files for example can be annotated as objects,
relationships, or their properties. To do the same from nested XML and JSON we
have provided an improved XMLLoader function (available in the Apache Piggy Bank
repository) to parse XML files, an ExtractJSONField UDF to extract JSON Path
matches from a JSON string and an RegexExtractAllMatches utility
which extracts all text matches in a string.

Once a graph is constructed the deduplication macro can be used to merge
duplicate elements. These capabilities can easily be extended writing
your own custom user defined function.

Of course, there’s no point in building a graph if it can’t be queried,
analyzed or visualized. So, we have introduced new bulk load and export
methods. The LOAD_TITAN macro bulk loads the open source Titan distributed
graph database via the Blueprints API so that the graphs can be explored
using the Gremlin query language. In addition, we have extended Graph Builder
to support the Resource Description Framework (RDF) export format. RDF
triples for property graph elements are formed using Apache Jena library.
We only export graphs in the N-TRIPLES format. All the Jena RDF
namespaces are accepted. Last, but not least this version of the Graph
Builder library can also export simple edge (object) lists and vertex
(relationship) lists. Graph visualization tools such as Gephi can be used with
the edge list exports.

How to build the Graph Builder?
-------------------------------
Intel Graph Builder uses Apache Maven v3.1.1 to compile and package. Please
ensure Maven3 is installed in the system.
To build package without running unit tests:
$> mvn clean package -DskipTests

To build package and run unit tests:
$> mvn clean package

To install Graph Builder:
$> mvn clean install

How to use the Graph Builder Library?
-------------------------------------

Please refer to the Pig scripts provided in the examples directory to run
different use cases of Graph Builder. The wikipedia_example.pig script
constructs a bipartite Link-Page graph from Wikipedia dataset (XML format).
The Wiki page dump containing pages in English language can be downloaded
from the following location:

http://download.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2

This size of the data is 9.5GB compressed and 44GB uncompressed. A smaller
version of the Wiki dump containing a subset of the pages can be downloaded
from:

http://dumps.wikimedia.org/enwiki/latest/enwiki
                -latest-pages-articles1.xml-p000000010p000010000.bz2

We have also provided a few toy data to demonstrate the functionality
of the UDF and macros provided in this distribution. They are in
examples/data directory.

---------------------------------------------------------------
* Please read the Known Issues section to resolve classpath   *
* exceptions and timeout problems                             *
---------------------------------------------------------------

Where will I get the documentation for Graph Builder 2.0?
---------------------------------------------------------

Prerequisites: Please install doxygen version 1.6.1 and use the following
command to generate HTML documentation pages:

$> mvn exec:exec

The documents are generated under docs/html directory.

Release Notes
-------------

+ Added following UDF's and MACRO's
  \ [CreatePropGraphElements]
  \ [CreateRowKey]
  \ [EdgeList]
  \ [ExtractJSONField]
  \ [FlattenAsGBString]
  \ [GetPropGraphElementID]
  \ [MergeDuplicateGraphElements]
  \ [RDF]
  \ [RegexExtractAllMatches]
  \ [VertexList]
+ Added TableToTitanGraph Java MapReduce code to bulk load property graph
  from HBase Tables to open source Titan graph database
- Removed ID Normalization and Partitioning
- Removed wordpage graph and linkgraph tokenizer from demoapps

Known Issues
------------

1. Hadoop classpath issues

The Apache(TM) Pig project uses Hadoop's classpath variable to load
required Java libraries. Apache(TM) Hadoop(TM) uses
$HADOOP_HOME/conf/hadoop-env.sh configuration file to manage the Java
classpaths and environment variables. To use Intel Graph Builder library,
please override the HADOOP_CLASSPATH as follows:

$> export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$PIG_HOME/pig-0.12.0
.jar:$GRAPHBUILDER_HOME/target/graphbuilder-2.0-alpha-wth-deps.jar

If $HADOOP_CLASSPATH is overwritten in the $HADOOP_HOME/conf/hadoop-env.sh
file, please ensure that it prepends existing jars in the Hadoop
classapth. This means, if the variable is overwritten as,

HADOOP_CLASSPATH=myjar.jar:otherjar.jar

please, use:

HADOOP_CLASSPATH=$HADOOP_CLASSPATH:myjar.jar:otherjar.jar

2. Tuning

We highly recommend to tune both Hadoop and HBase installation to
successfully create large graphs (typically more than a million edges or
vertices). In a 16-node cluster with 64GB RAM and Intel Xeon processors,
we used the following configuration parameter values for HBase to create a
link-page graph from the Wikipedia English language data (link provided
earlier):

- hbase-site.xml

  <property>
    <name>hbase.zookeeper.property.maxClientCnxns</name>
    <value>5000</value>
  </property>

  <property>
    <name>zookeeper.session.timeout</name>
    <value>6000000</value>
  </property>

  <property>
    <name>hbase.hregion.max.filesize</name>
    <value>1073741824</value>
  </property>

  <property>
    <name>hbase.rpc.timeout</name>
    <value>6000000</value>
  </property>




