--------
Overview
--------

.. outdated::

    Big data is transforming industries and research, and spawning new solutions for addressing a wide range of societal challenges.
    Big data strategies require software with abilities to capture the growing volume and diversity of data, and analyze it.
    These programs need to provide massive scalability, cost effectiveness, and a vibrant open source ecosystem.
    Hadoop is one of the solutions to these problems.
    However, once data has been obtained, achieving business insights remains complicated.
    Scarcity in data science expertise is exacerbated by the myriad of open source tools.
    The resulting workflows become inefficient for iteration and collaboration, and existing tools are often geared towards answering known questions, with limited methods to discover signals from the connections prevalent in big data.

Big data has transformed industries and research, spawning new solutions for addressing a wide range of technical challenges.
In this domain, end-to-end analytic strategies typically begin by data capture and storage on either a distributed computing network, or HPC environment of some kind.
However, once data has been obtained, achieving business insights has proven difficult and expensive.
Furthermore, the fractionated nature of the data analytic software ecosystem has caused analytical workflows to become inefficient for iteration and collaboration, while existing tools tend to be geared toward answering known questions, with limited software being available for exploring large, complex data sets.

The |IAT| mitigates the difficulties associated with big data analytics, by enabling data scientists to efficiently work with their data.
An intuitive programming environment facilitates end-to-end analytic workflows that foster collaboration, iteration, and better time-to-deployment.
Data scientists are able to focus on analytical issues, doing their code work in a single programming environment, without the need to master low-level programming languages.
The toolkit unifies entity-based machine learning with end-to-end graph processing, and includes powerful, scalable algorithms for discovering relationships in big data, and the modular framework enables users to extend and integrate new functionality and algorithms.

