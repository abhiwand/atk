register target/IntelGraphAnalytics-0.0.1-SNAPSHOT-jar-with-dependencies.jar                
DEFINE ArcLoader com.intel.graph.analytics.examples.ArcLoader();
DEFINE ExtractText com.intel.graph.analytics.examples.ExtractText();
DEFINE RemoveSymbols com.intel.graph.analytics.examples.RemoveSymbols();
DEFINE RemoveNums com.intel.graph.analytics.examples.RemoveNums();
DEFINE RowKeyAssignerUDF com.intel.graph.analytics.examples.LDARowKeyAssignerUDF();


raw_data = LOAD '/user/mohitdee/arc_data/100.arc.gz' USING ArcLoader() AS (url:chararray, timestamp:chararray, content:chararray);
url_text = FOREACH raw_data GENERATE url AS url, FLATTEN(ExtractText(content)) AS text;

lower_flatten = FOREACH url_text GENERATE url, LOWER(text) as lower_clean_text: chararray;
--limited = LIMIT lower_flatten 2;

clean_symbols = FOREACH lower_flatten GENERATE url, RemoveSymbols(lower_clean_text) as cleaned_text:chararray;
clean_numerics = FOREACH clean_symbols GENERATE url, RemoveNums(cleaned_text) as cleaned_text:chararray;

splitted_text = FOREACH clean_numerics GENERATE url,'d' as identifier, FLATTEN(TOKENIZE(cleaned_text)) as tokens;

-- remove common words from analysis
stop_words = LOAD '/user/user/stop_words.txt' USING PigStorage('\n') AS (words:chararray);
exclude = JOIN splitted_text By tokens LEFT OUTER, stop_words BY words USING 'replicated';
remove = filter exclude by words IS NULL;
flatten_remove = foreach remove generate url,identifier, tokens; 

-- remove words based on word length
filter_small_words = FILTER  flatten_remove BY SIZE(tokens) >4;

--giraph requires edges to be bidirectional
flip_edges = FOREACH filter_small_words GENERATE tokens as url,'w' as identifier, url as tokens;
unioned = UNION filter_small_words,flip_edges;

generated = FOREACH unioned GENERATE url as id1, identifier as identifier, tokens as id2;

grouped = GROUP generated BY (id1,id2,identifier);      

graph = FOREACH grouped GENERATE group.id1, group.id2, COUNT(generated) AS num,group.identifier;



-- things starts getting murkier
-- writing to titan
with_hbase_keys = FOREACH graph GENERATE RowKeyAssignerUDF(*);

final_graph = FOREACH with_hbase_keys GENERATE FLATTEN($0) 
			  AS (key:chararray, id1:chararray,  id2:chararray, num:long, identifier:chararray);



DEFINE STORE_GRAPH(lda_demo, hbase_out_table, graph_db) RETURNS void {
  stored_graph = MAPREDUCE 'graphbuilder-2.0-hadoop-job.jar' STORE final_graph INTO 'hbase://lda_demo' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cf:id1 cf:id2 cf:num cf:identifer') 
  LOAD '/tmp/empty' using TextLoader() as (line:chararray) `com.intel.hadoop.graphbuilder.sampleapplications.TableToGraphDB -conf hbaseToTitan.xml -t lda_demo -v "cf:id1=cf:identifier"  "cf:id2=cf:num" -e "cf:id1, cf:id2,link"`;
  STORE stored_graph INTO '/tmp/tmp_store';
};
STORE_GRAPH(final_graph, 'hbase://lda_demo', 'Titan');



