
// config file for running integration tests

intel.analytics {

  // were using a different port so it won't interfere with a running local server
  api.port = 19099

  // use H2 for testing so that we'll have a fresh DB each time
  metastore.connection = ${intel.analytics.metastore.connection-h2}

  engine {

    // TODO: Titan is not yet working
    // use Berkley for backing Titan, requires extra code in application to set storage.directory
    titan.load.storage.hostname = ""
    titan.load.storage.backend = "berkeleyje"
    titan.query.storage.hostname = ${intel.analytics.engine.titan.load.storage.hostname}
    titan.query.storage.backend = "berkeleyje"

    spark {
      # The URL for connecting to the Spark master server
      master = "local[8]"

      # true to re-use a local SparkContext, this can be helpful for automated integration tests, not for customers.
      reuse-local-context = true
    }
  }
}