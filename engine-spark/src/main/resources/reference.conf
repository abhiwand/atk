intel.analytics.component.archives {
  engine-spark {
    config-path = "intel.analytics.engine-spark"
  }
}

intel.analytics {
  metastore {
    connection {
      // H2 is a in-memory Java database useful for testing
      url = "jdbc:h2:mem:iatest;DB_CLOSE_DELAY=-1"
      driver = "org.h2.Driver"
      username = "" // leave blank, no user or password is needed for H2
      password = "" // leave blank, no user or password is needed for H2

      // PostgreSQL is an open source database that comes with Cloudera
      //url = "jdbc:postgresql://localhost:5432/metastore"
      //driver = "org.postgresql.Driver"
      //username = "metastore"
      //password = "Tribeca123"
    }
  }

  engine {

    default-timeout = 30
    max-rows = 500

    fs {
      # the system will create an "intelanalytics" folder at this location, if set,
      # or at the root of the filesystem, if not. All Intel Analytics Toolkit files will
      # be stored somehwere under that base location.
      #
      # For example, if using HDFS, set the root to hdfs path
      # root = "hdfs://MASTER_HOSTNAME/some/path"
      #
      # If running in local mode, this might be a better choice:
      # root = ${user.home}

      root = "hdfs://master/user/iauser"
    }

    spark {

      // When master is empty the system defaults to spark://`hostname`:7070 where hostname is calculated from the current system
      master = ""
      // When home is empty the system will check expected locations on the local system and use the first one it finds
      // ("/usr/lib/spark","/opt/cloudera/parcels/CDH/lib/spark/", etc)
      home = ""

      // in cluster mode, set master and home like the example
      // master = "spark://MASTER_HOSTNAME:7077"
      // home = "/opt/cloudera/parcels/CDH/lib/spark"
      // home = "/usr/lib/spark"

      // local mode
      // master = "local[4]"

      // this is the default number of partitions that will be used for RDDs
      defaultPartitions = 90


      // path to python worker execution, usually to toggle 2.6 and 2.7
      //pythonWorkerExec = "python2.7"
      pythonWorkerExec = "python"

      conf {
        properties {
          // These key/value pairs will be parsed dynamica2ostlly and provided to SparkConf()
          // See Spark docs for possible values http://spark.apache.org/docs/0.9.0/configuration.html
          // All values should be convertible to Strings

          //spark.akka.frameSize=10000
          //spark.akka.retry.wait=30000
          //spark.akka.timeout=200
          //spark.akka.timeout=30000

          // Memory should be same or lower than what is listed as available in Cloudera Manager
          //spark.executor.memory = "16g"
          spark.executor.memory = "8g"

          //spark.shuffle.consolidateFiles=true

          //spark.storage.blockManagerHeartBeatMs=300000
          //spark.storage.blockManagerSlaveTimeoutMs=300000

          //spark.worker.timeout=600
          //spark.worker.timeout=30000
        }

      }
    }


  // TODO: where is the right place for this to go?  Looks like it was commented out below.
  commands {
    dataframes {
        create {
        }
        load {
            // number of rows taken for sample test during frame loading
            schema-validation-sample-rows = 100

            // percentage of maximum rows fail in parsing in sampling test. 50 means up 50% is allowed
            schema-validation-fail-threshold-percentage = 50
        }

    }
  }

    commands {
      dataframes.create = {}
      graphs.ml {

      alternating_least_squares {
        fs = ${intel.analytics.engine.fs}
        default-timeout = ${intel.analytics.engine.default-timeout}
        giraph = ${intel.analytics.engine.giraph}
        titan = ${intel.analytics.engine.titan}
        output {
          dir = "als"
          overwrite = "true"
        }
        giraph {
          als.maxSuperSteps = 20
          als.convergenceThreshold = 0
          als.lambda = 0.065f
          als.featureDimension = 3
          als.learningCurveOutputInterval = 1
          als.bidirectionalCheck = false
          als.biasOn = false
          als.maxVal = "Infinity"
          als.minVal = "Infinity"
        }
      }

      conjugate_gradient_descent {
        fs = ${intel.analytics.engine.fs}
        default-timeout = ${intel.analytics.engine.default-timeout}
        giraph = ${intel.analytics.engine.giraph}
        titan = ${intel.analytics.engine.titan}
        output {
          dir = "cgd"
          overwrite = "true"
        }
        giraph {
          cgd.maxSuperSteps = 20
          cgd.convergenceThreshold = 0
          cgd.lambda = 0.065f
          cgd.featureDimension = 3
          cgd.learningCurveOutputInterval = 1
          cgd.bidirectionalCheck = false
          cgd.biasOn = false
          cgd.maxVal = "Infinity"
          cgd.minVal = "-Infinity"
          cgd.numCGDIters = 5
        }
      }

      label_propagation {
        fs = ${intel.analytics.engine.fs}
        default-timeout = ${intel.analytics.engine.default-timeout}
        giraph = ${intel.analytics.engine.giraph}
        titan = ${intel.analytics.engine.titan}
        output {
          dir = "lp"
          overwrite = "true"
        }
      }

      loopy_belief_propagation {
        fs = ${intel.analytics.engine.fs}
        default-timeout = ${intel.analytics.engine.default-timeout}
        giraph = ${intel.analytics.engine.giraph}
        titan = ${intel.analytics.engine.titan}
        output {
          dir = "lbp"
          overwrite = "true"
        }
        giraph {
          lbp.maxSuperSteps = 10
          lbp.convergenceThreshold = 0
          lbp.anchorThreshold = 0.9
          lbp.bidirectionalCheck = false
          lbp.power = 0.5
          lbp.smoothing = 2.0
          lbp.ignoreVertexType = false
        }
      }
	  }
      graphs.query {
      histogram_roc {
        default-timeout = ${intel.analytics.engine.default-timeout}
        titan = ${intel.analytics.engine.titan}
        histogram-buckets = 30
        enable-roc = "false"
        roc-threshold = [0, 0.05, 1]
      }
    }
    }

    //  query {
    //    ALSQuery {
    //      key-name = "id"
    //      vertex-type-name = "vertex_type"
    //      bias-on = true
    //      edge-type-name = "edge_type"
    //      edge-type = "edge"
    //      feature-dimensions = 1
    //      left-type = "L"
    //      right-type = "R"
    //      left-name = "user"
    //      right-name = "item"
    //      result-property-list = "als_p0;als_p1;als_p3;als_bias"
    //      train = "TR"
    //    }
    //  }

    titan {
      load {
        // documentation for these settings is available on Titan website
        storage {
          backend = "hbase"
          // with clusters the hostname should be a comma separated list of host names with zookeeper role assigned
          hostname = "master"
          port = "2181"
          batch-loading = "true"
          buffer-size = 2048
          attempt-wait = 300
          lock-wait-time = 400
          lock-retries = 15
          idauthority-retries = 30
          read-attempts = 6
          // Pre-split settngs for large datasets
          // region-count = 100
          // short-cf-names = "true"

        }

        autotype = "none"

        ids {
          block-size = 300000
          renew-timeout = 150000
        }
      }
      query {
        storage {
          // query does use the batch load settings in titan.load
          // TODO: should these variables be under intel.analytics.engine.titan or is this ok?
          backend = ${intel.analytics.engine.titan.load.storage.backend}
          hostname = ${intel.analytics.engine.titan.load.storage.hostname}
          port = ${intel.analytics.engine.titan.load.storage.port}
        }
        cache {
          // Adjust cache size parameters if you experience OutOfMemory errors during Titan queries
          // Either increase heap allocation for IntelAnalytics Engine, or reduce db-cache-size
          // Reducing db-cache will result in cache misses and increased reads from disk
          db-cache = true
          db-cache-clean-wait = 20
          db-cache-time = 180000
          db-cache-size = 0.3 //Allocates 30% of available heap to Titan (default is 50%)
        }
      }
    }
  }

}

intel.analytics.engine-spark {
  command {
    available = ["graphs.query.gremlin", "graphs.query.histogram_roc"]
    graphs {
      query {
        gremlin {
          class = "com.intel.intelanalytics.engine.spark.graph.query.GremlinQuery"
          config {
            default-timeout = ${intel.analytics.engine.default-timeout}
            titan = ${intel.analytics.engine.titan}
            graphson-mode = "normal" // Valid values: "normal", "compact", "extended"
          }
        }
        histogram_roc {
          class = "com.intel.intelanalytics.engine.spark.graph.query.roc.HistogramRocQuery"
          config {
            default-timeout = ${intel.analytics.engine.default-timeout}
            titan = ${intel.analytics.engine.titan}
            histogram-buckets = 30
            enable-roc = "false"
            roc-threshold = [0, 0.05, 1]
          }
        }
      }
    }
  }

  auto-partitioner {
    // auto-partitioning takes a best guess based on the file size
    file-size-to-partition-size = [{ upper-bound="1MB", partitions = 30 }
                                   { upper-bound="1GB", partitions = 90 },
                                   { upper-bound="5GB", partitions = 200 },
                                   { upper-bound="10GB", partitions = 400 },
                                   { upper-bound="15GB", partitions = 750 },
                                   { upper-bound="25GB", partitions = 1000 },
                                   { upper-bound="50GB", partitions = 1500 },
                                   { upper-bound="100GB", partitions = 2000 },
                                   { upper-bound="200GB", partitions = 3000 },
                                   { upper-bound="300GB", partitions = 4000 },
                                   { upper-bound="400GB", partitions = 5000 },
                                   { upper-bound="600GB", partitions = 7500 }]

    // max-partitions is used if value is above the max upper-bound
    max-partitions = 10000
  }
}
