#collected these variables here so that we can create this file from another process and call Pig to do the ETL
#this will be helpful if we want to wire a GUI in front of Pig later
REGISTER_STATEMENT='custom-parsers/shaw_udfs.py USING jython as shaw_udfs'
CUSTOM_PARSER='shaw_udfs.parseRecord(*)'
INPUT_DELIM='\\n'
OUTPUT_FILE=/tmp/shaw_processed_csv
TRANSFORMED_OUTPUT=/tmp/shaw_standardized
INPUT_FILE=test-data/shaw_in
#INPUT_FILE=/tmp/shaw_usage_20120627.log
SCHEMA_DEF='(timestamp: chararray, event_type: chararray, method: chararray, duration: double, item_id: chararray, src_tms: chararray, dst_tms: chararray)'
DEGREE_OF_PARALLELISM=16
FIELD_EXTRACTORS='$0.timestamp, $0.event_type, $0.method, $0.duration, $0.item_id, $0.src_tms, $0.dst_tms'
OUTPUT_DELIM=','
CLEAN_FIELD=duration
NORMALIZATION_FIELD=duration
NORMALIZED_FIELDS='$0.timestamp, $0.event_type, $0.method, ($0.duration - avg_var_relation.$0)/stddev_relation.stddev as normalized_duration, $0.item_id, $0.src_tms, $0.dst_tms'
